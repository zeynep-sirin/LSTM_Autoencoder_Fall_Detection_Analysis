{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2693d97b-e462-4681-9184-763847f84799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This project employed a Deep Learning \n",
    "#methodology using TensorFlow and Keras  \n",
    "#to perform Anomaly Detection for critical Fall Detection. \n",
    "#The system is built upon an LSTM Autoencoder architecture. \n",
    "#This model is trained exclusively on normal human activity data, \n",
    "#allowing it to learn and reconstruct the characteristic patterns of non-fall movements. \n",
    "#Any significant deviation or high reconstruction error between the input sequence \n",
    "#and the reconstructed output is flagged as an anomaly, indicating a potential fall event. \n",
    "#This analysis relies on open-source data voluntarily sourced from Kaggle.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b816bc1-eaca-4baa-ab3d-5e7bcd1c78e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, RepeatVector, TimeDistributed\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f133aa78-78aa-4d12-a11a-052693f5212e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data rows: 164284\n",
      "Number of features: 7 (Expected: 7)\n",
      "Label distribution (0=Normal, 1=Anomaly):\n",
      "7\n",
      "0.0        156076\n",
      "1.0          8183\n",
      "anomaly        25\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define the dataset file path\n",
    "DATA_DIR = \"/Users/zey/Downloads/data\"\n",
    "\n",
    "# Find paths of all .csv files, including subfolders (\"train\" and \"test\")\n",
    "all_files = glob.glob(os.path.join(DATA_DIR, \"**/*.csv\"), recursive=True)\n",
    "\n",
    "df_list = [] # Renamed list to df_list\n",
    "for filename in all_files:\n",
    "    # Read CSV files, header=None as there are no column names\n",
    "    df = pd.read_csv(filename, index_col=None, header=None)\n",
    "    df_list.append(df)\n",
    "\n",
    "# Merge all DataFrames vertically (row by row)\n",
    "full_df = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "\n",
    "# Separate columns: 7 Features (X,Y,Z + 4 OHE Sensors) and 1 Label\n",
    "NUM_FEATURES = 7 \n",
    "LABEL_COLUMN_INDEX = NUM_FEATURES # The 8th column (Index 7) is the Label\n",
    "\n",
    "features = full_df.iloc[:, 0:LABEL_COLUMN_INDEX] # Features (Columns 0 to 6)\n",
    "labels = full_df.iloc[:, LABEL_COLUMN_INDEX]     # Labels (Column 7)\n",
    "\n",
    "print(f\"Total data rows: {len(full_df)}\")\n",
    "print(f\"Number of features: {features.shape[1]} (Expected: 7)\")\n",
    "print(f\"Label distribution (0=Normal, 1=Anomaly):\\n{labels.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dcb88a2-2a48-4324-b798-99bdc11a69df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of normalized 'Normal' data rows for training: 156076\n"
     ]
    }
   ],
   "source": [
    "# --- SECTION 2.1: DATA PREPROCESSING \n",
    "# 1. Cleaning\n",
    "features_cleaned = features.apply(pd.to_numeric, errors='coerce')\n",
    "features_cleaned = features_cleaned.dropna()\n",
    "labels_cleaned = labels[features_cleaned.index]\n",
    "\n",
    "# 2. NumPy Values\n",
    "features_values = features_cleaned.values\n",
    "labels_values = labels_cleaned.values\n",
    "\n",
    "# 3. Scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data_numpy = scaler.fit_transform(features_values)\n",
    "\n",
    "# 4. \n",
    "NORMAL_LABEL = 0\n",
    "\n",
    "is_normal = (labels_values.astype(float).astype(int) == NORMAL_LABEL)\n",
    "train_data_scaled = scaled_data_numpy[is_normal]\n",
    "\n",
    "print(f\"Number of normalized 'Normal' data rows for training: {len(train_data_scaled)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78fdd2d3-138d-4b13-8348-382b76f803cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window Size: 50\n",
      "Training Data Shape (Number of Sequences, Window Size, Number of Features): (156027, 50, 7)\n"
     ]
    }
   ],
   "source": [
    "WINDOW_SIZE = 50 \n",
    "\n",
    "def create_sequences(data, window_size):\n",
    "    \"\"\"Divides the given time series data into sequences of the specified window size.\"\"\"\n",
    "    sequences = []\n",
    "    for i in range(len(data) - window_size + 1):\n",
    "        sequences.append(data[i:i + window_size])\n",
    "    return np.array(sequences)\n",
    "\n",
    "# Convert the normal training data into 3D sequences\n",
    "X_train = create_sequences(train_data_scaled, WINDOW_SIZE)\n",
    "\n",
    "print(f\"Window Size: {WINDOW_SIZE}\")\n",
    "print(f\"Training Data Shape (Number of Sequences, Window Size, Number of Features): {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6797aeeb-3021-434e-9f79-28062070ea68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">69,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">903</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m69,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m7\u001b[0m)          │           \u001b[38;5;34m903\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">202,119</span> (789.53 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m202,119\u001b[0m (789.53 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">202,119</span> (789.53 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m202,119\u001b[0m (789.53 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, RepeatVector, TimeDistributed\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "NUM_FEATURES = X_train.shape[2] \n",
    "\n",
    "def create_lstm_autoencoder(window_size, num_features):\n",
    "    model = Sequential([\n",
    "        # --- ENCODER ---\n",
    "        LSTM(units=128, activation='relu', input_shape=(window_size, num_features)),\n",
    "        RepeatVector(window_size),\n",
    "        \n",
    "        # --- DECODER ---\n",
    "        LSTM(units=128, activation='relu', return_sequences=True),\n",
    "        TimeDistributed(Dense(num_features))\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "model = create_lstm_autoencoder(WINDOW_SIZE, NUM_FEATURES)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40755bbb-95f5-473d-8cf4-13e73e7cdcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training Started...\n",
      "Epoch 1/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 36ms/step - loss: 0.1110 - val_loss: 0.1105\n",
      "Epoch 2/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 35ms/step - loss: 0.1074 - val_loss: 0.1088\n",
      "Epoch 3/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 34ms/step - loss: 0.1070 - val_loss: 0.1082\n",
      "Epoch 4/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 35ms/step - loss: 0.1067 - val_loss: 0.1081\n",
      "Epoch 5/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 34ms/step - loss: 0.1065 - val_loss: 0.1081\n",
      "Epoch 6/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 35ms/step - loss: 0.1064 - val_loss: 0.1080\n",
      "Epoch 7/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 34ms/step - loss: 0.1062 - val_loss: 0.1079\n",
      "Epoch 8/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 34ms/step - loss: 0.1060 - val_loss: 0.1074\n",
      "Epoch 9/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 36ms/step - loss: 0.1058 - val_loss: 0.1071\n",
      "Epoch 10/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 36ms/step - loss: 0.1057 - val_loss: 0.1066\n",
      "Epoch 11/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 38ms/step - loss: 0.1055 - val_loss: 0.1068\n",
      "Epoch 12/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 37ms/step - loss: 0.1041 - val_loss: 0.1074\n",
      "Epoch 13/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 35ms/step - loss: 0.1013 - val_loss: 0.1078\n",
      "Epoch 14/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 38ms/step - loss: 0.0968 - val_loss: 0.1086\n",
      "Epoch 15/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 37ms/step - loss: 0.0887 - val_loss: 0.1092\n",
      "Epoch 16/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 36ms/step - loss: 0.0807 - val_loss: 0.1055\n",
      "Epoch 17/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 36ms/step - loss: 0.0755 - val_loss: 0.1014\n",
      "Epoch 18/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 37ms/step - loss: 0.0715 - val_loss: 0.0998\n",
      "Epoch 19/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 37ms/step - loss: 0.0683 - val_loss: 0.0965\n",
      "Epoch 20/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 36ms/step - loss: 0.0661 - val_loss: 0.0940\n",
      "Epoch 21/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 35ms/step - loss: 0.0634 - val_loss: 0.0941\n",
      "Epoch 22/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 35ms/step - loss: 0.0614 - val_loss: 0.0927\n",
      "Epoch 23/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 35ms/step - loss: 0.0588 - val_loss: 0.0931\n",
      "Epoch 24/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 34ms/step - loss: 0.0572 - val_loss: 0.0926\n",
      "Epoch 25/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 37ms/step - loss: 0.0544 - val_loss: 0.0914\n",
      "Epoch 26/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 36ms/step - loss: 0.0520 - val_loss: 0.0915\n",
      "Epoch 27/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 35ms/step - loss: 0.0503 - val_loss: 0.0921\n",
      "Epoch 28/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 33ms/step - loss: 0.0476 - val_loss: 0.0899\n",
      "Epoch 29/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 36ms/step - loss: 0.0450 - val_loss: 0.0861\n",
      "Epoch 30/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 36ms/step - loss: 0.0424 - val_loss: 0.0844\n",
      "Epoch 31/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 39ms/step - loss: 0.0408 - val_loss: 0.0829\n",
      "Epoch 32/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 40ms/step - loss: 0.0394 - val_loss: 0.0826\n",
      "Epoch 33/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 39ms/step - loss: 0.0384 - val_loss: 0.0822\n",
      "Epoch 34/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 38ms/step - loss: 0.0375 - val_loss: 0.0818\n",
      "Epoch 35/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 35ms/step - loss: 0.0365 - val_loss: 0.0821\n",
      "Epoch 36/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 38ms/step - loss: 0.0358 - val_loss: 0.0796\n",
      "Epoch 37/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 36ms/step - loss: 0.0354 - val_loss: 0.0793\n",
      "Epoch 38/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 39ms/step - loss: 0.0358 - val_loss: 0.0806\n",
      "Epoch 39/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 39ms/step - loss: 0.0342 - val_loss: 0.0807\n",
      "Epoch 40/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 38ms/step - loss: 0.0352 - val_loss: 0.0814\n",
      "Epoch 41/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 41ms/step - loss: 0.0340 - val_loss: 0.0796\n",
      "Epoch 42/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 38ms/step - loss: 0.0326 - val_loss: 0.0814\n",
      "Epoch 43/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 39ms/step - loss: 0.0325 - val_loss: 0.0805\n",
      "Epoch 44/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 38ms/step - loss: 0.0320 - val_loss: 0.0817\n",
      "Epoch 45/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 38ms/step - loss: 0.0316 - val_loss: 0.0822\n",
      "Epoch 46/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 39ms/step - loss: 0.0310 - val_loss: 0.0820\n",
      "Epoch 47/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 40ms/step - loss: 0.0303 - val_loss: 0.0815\n",
      "Epoch 48/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 41ms/step - loss: 0.0294 - val_loss: 0.0818\n",
      "Epoch 49/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 41ms/step - loss: 0.0292 - val_loss: 0.0807\n",
      "Epoch 50/50\n",
      "\u001b[1m4389/4389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 38ms/step - loss: 0.0287 - val_loss: 0.0804\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Model Training Started...\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, X_train, \n",
    "    epochs=50,         \n",
    "    batch_size=32,\n",
    "    validation_split=0.1, \n",
    "    shuffle=False      \n",
    ")\n",
    "\n",
    "# Eğitim Kaybı Görselleştirme\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('LSTM Autoencoder Loss Plot (Training Process)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "534590e3-d4cc-4890-a949-f5538d411267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test sequences (Normal + Anomaly): 164210\n",
      "Total number of true labels: 164210\n",
      "\u001b[1m5132/5132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 9ms/step\n",
      "Reconstruction Loss Calculated and DataFrame created.\n"
     ]
    }
   ],
   "source": [
    "# --- TEST DATA PREPARATION AND RECONSTRUCTION LOSS ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, recall_score\n",
    "\n",
    "# --- NOTE ---\n",
    "# This code assumes the variables 'scaled_data_numpy' and 'labels_values' \n",
    "# are defined in the preceding cell and are available in memory.\n",
    "# It also assumes WINDOW_SIZE is defined (e.g., WINDOW_SIZE = 50).\n",
    "\n",
    "# 1. Convert all data (normal + anomaly) into sequences\n",
    "X_all = create_sequences(scaled_data_numpy, WINDOW_SIZE)\n",
    "\n",
    "# 2. Prepare the true labels for the sequences\n",
    "# The labels must be aligned with the sequences (y_true corresponds to the end of each sequence)\n",
    "# We use 'labels_values' (the correct variable name from Section 2.1)\n",
    "y_true = labels_values.astype(float).astype(int)[WINDOW_SIZE - 1:]\n",
    "\n",
    "print(f\"Total number of test sequences (Normal + Anomaly): {X_all.shape[0]}\")\n",
    "print(f\"Total number of true labels: {len(y_true)}\")\n",
    "\n",
    "# 3. Reconstruct all sequences using the trained model\n",
    "X_pred = model.predict(X_all)\n",
    "\n",
    "# 4. Calculate the Reconstruction Error (Mean Squared Error across all features and time steps)\n",
    "mse_loss = np.mean(np.square(X_all - X_pred), axis=(1, 2))\n",
    "\n",
    "# 5. Create the Error DataFrame for analysis\n",
    "error_df = pd.DataFrame({'Reconstruction_Error': mse_loss, 'True_Class': y_true})\n",
    "\n",
    "print(\"Reconstruction Loss Calculated and DataFrame created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad8db42a-d2c7-4025-8f00-7f1e50b1d347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Anomaly Threshold (95th percentile of Normal Loss): 0.099398\n",
      "\n",
      "--- ANOMALY DETECTION RESULTS ---\n",
      "Confusion Matrix:\n",
      "[[148225   7802]\n",
      " [  7926    257]]\n",
      "Accuracy: 0.9042\n",
      "F1 Score: 0.0316\n",
      "Recall (Sensitivity): 0.0314\n"
     ]
    }
   ],
   "source": [
    "# ---  THRESHOLD AND EVALUATION ---\n",
    "# (Assumes error_df was created in the previous step)\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, recall_score\n",
    "\n",
    "#  Determine Anomaly Threshold (using 95th percentile of normal loss)\n",
    "\n",
    "normal_loss = error_df[error_df['True_Class'] == 0]['Reconstruction_Error']\n",
    "\n",
    "\n",
    "THRESHOLD = np.quantile(normal_loss, 0.95) \n",
    "\n",
    "print(f\"\\nAnomaly Threshold (95th percentile of Normal Loss): {THRESHOLD:.6f}\")\n",
    "\n",
    "#  Predict Anomalies and Evaluate\n",
    "\n",
    "error_df['Predicted_Class'] = (error_df['Reconstruction_Error'] > THRESHOLD).astype(int)\n",
    "\n",
    "# Calculated matrixes\n",
    "conf_matrix = confusion_matrix(error_df['True_Class'], error_df['Predicted_Class'])\n",
    "accuracy = accuracy_score(error_df['True_Class'], error_df['Predicted_Class'])\n",
    "f1 = f1_score(error_df['True_Class'], error_df['Predicted_Class'])\n",
    "recall = recall_score(error_df['True_Class'], error_df['Predicted_Class'])\n",
    "\n",
    "print(\"\\n--- ANOMALY DETECTION RESULTS ---\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Recall (Sensitivity): {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "621c1d25-8ae1-4665-aabe-e58b2342d7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Anomaly Threshold (99th percentile of Normal Loss): 0.110549\n",
      "\n",
      "--- ANOMALY DETECTION RESULTS (99th Percentile Threshold) ---\n",
      "Confusion Matrix:\n",
      "[[154466   1561]\n",
      " [  8136     47]]\n",
      "Accuracy: 0.9409\n",
      "F1 Score: 0.0096\n",
      "Recall (Sensitivity): 0.0057\n"
     ]
    }
   ],
   "source": [
    "#While the model was successful in recognizing normal activity (high TN), \n",
    "#it was insufficient in detecting abnormal activity (falls) (low Recall and F1 Score).\n",
    "\n",
    "# --- : RE-EVALUATION (99th PERCENTILE THRESHOLD) ---\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, recall_score\n",
    "\n",
    "\n",
    "\n",
    "# Determine Anomaly Threshold using the 99th percentile (Stricter threshold)\n",
    "THRESHOLD_99 = np.quantile(normal_loss, 0.99) \n",
    "\n",
    "print(f\"New Anomaly Threshold (99th percentile of Normal Loss): {THRESHOLD_99:.6f}\")\n",
    "\n",
    "# Predict Anomalies based on the new threshold\n",
    "# Reconstruction error > THRESHOLD_99 is classified as Anomaly (1)\n",
    "error_df['Predicted_Class_99'] = (error_df['Reconstruction_Error'] > THRESHOLD_99).astype(int)\n",
    "\n",
    "# Calculate and Print Metrics\n",
    "conf_matrix_99 = confusion_matrix(error_df['True_Class'], error_df['Predicted_Class_99'])\n",
    "accuracy_99 = accuracy_score(error_df['True_Class'], error_df['Predicted_Class_99'])\n",
    "f1_99 = f1_score(error_df['True_Class'], error_df['Predicted_Class_99'])\n",
    "recall_99 = recall_score(error_df['True_Class'], error_df['Predicted_Class_99'])\n",
    "\n",
    "print(\"\\n--- ANOMALY DETECTION RESULTS (99th Percentile Threshold) ---\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix_99}\")\n",
    "print(f\"Accuracy: {accuracy_99:.4f}\")\n",
    "print(f\"F1 Score: {f1_99:.4f}\")\n",
    "print(f\"Recall (Sensitivity): {recall_99:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97b6be57-8013-4f14-a723-4a7c99342eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Window Size: 100\n",
      "Training Data Shape (New Window Size, Number of Features): (155977, 100, 7)\n"
     ]
    }
   ],
   "source": [
    "#Increasing the threshold from 0.099 to 0.110 made the model overly conservative. \n",
    "#While the model now makes very few errors on normal events (low FP), it misses almost all true fall events (Recall only 0.57%). \n",
    "#This is unacceptable performance for a critical task like fall detection.\n",
    "\n",
    "# --- NEW WINDOW_SIZE ---\n",
    "WINDOW_SIZE = 100\n",
    "print(f\"New Window Size: {WINDOW_SIZE}\")\n",
    "\n",
    "# --- Section 2.2 Re-run ---\n",
    "# Convert the normal training data into 3D sequences using the new window size\n",
    "\n",
    "X_train = create_sequences(train_data_scaled, WINDOW_SIZE) \n",
    "\n",
    "print(f\"Training Data Shape (New Window Size, Number of Features): {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec47a18d-7574-4e28-b05f-1326730e4153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">69,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">903</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m69,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector_1 (\u001b[38;5;33mRepeatVector\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │           \u001b[38;5;34m903\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">202,119</span> (789.53 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m202,119\u001b[0m (789.53 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">202,119</span> (789.53 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m202,119\u001b[0m (789.53 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been successfully rebuilt with a new input shape (100, 7).\n"
     ]
    }
   ],
   "source": [
    "# --- STEP 3: REBUILD THE MODEL ---\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, RepeatVector, TimeDistributed\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "\n",
    "# Set the new WINDOW_SIZE and the number of features (7 sensors)\n",
    "WINDOW_SIZE = 100\n",
    "NUM_FEATURES = 7 \n",
    "\n",
    "def create_lstm_autoencoder(window_size, num_features):\n",
    "    # Model architecture remains the same, only input_shape changes\n",
    "    model = Sequential([\n",
    "        LSTM(units=128, activation='relu', input_shape=(window_size, num_features)),\n",
    "        RepeatVector(window_size),\n",
    "        LSTM(units=128, activation='relu', return_sequences=True),\n",
    "        TimeDistributed(Dense(num_features))\n",
    "    ])\n",
    "    # Use the Adam optimizer and Mean Squared Error (MSE) loss\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "model = create_lstm_autoencoder(WINDOW_SIZE, NUM_FEATURES)\n",
    "model.summary()\n",
    "\n",
    "print(\"Model has been successfully rebuilt with a new input shape (100, 7).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2adb93fe-a1fe-4b4c-99e3-40ab80fa315b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">69,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">903</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m69,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector_2 (\u001b[38;5;33mRepeatVector\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │           \u001b[38;5;34m903\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">202,119</span> (789.53 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m202,119\u001b[0m (789.53 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">202,119</span> (789.53 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m202,119\u001b[0m (789.53 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model has been successfully rebuilt with a lower learning rate (0.0001).\n"
     ]
    }
   ],
   "source": [
    "## ---  REBUILD MODEL WITH LOWER LEARNING RATE ---\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, RepeatVector, TimeDistributed\n",
    "\n",
    "# Assuming WINDOW_SIZE = 100 and NUM_FEATURES = 7 are defined globally.\n",
    "\n",
    "def create_lstm_autoencoder_fixed(window_size, num_features):\n",
    "    model = Sequential([\n",
    "        LSTM(units=128, activation='relu', input_shape=(window_size, num_features)),\n",
    "        RepeatVector(window_size),\n",
    "        LSTM(units=128, activation='relu', return_sequences=True),\n",
    "        TimeDistributed(Dense(num_features))\n",
    "    ])\n",
    "    # FIX: Learning Rate reduced from 0.001 to 0.0001 to prevent 'nan' loss.\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='mse')\n",
    "    return model\n",
    "\n",
    "model = create_lstm_autoencoder_fixed(WINDOW_SIZE, NUM_FEATURES)\n",
    "model.summary()\n",
    "print(\"\\nModel has been successfully rebuilt with a lower learning rate (0.0001).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ff67d1c-9a5e-44bd-831d-92eb1b4d67d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Training Started with FIXED LEARNING_RATE=0.0001...\n",
      "Epoch 1/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m391s\u001b[0m 89ms/step - loss: 0.1123 - val_loss: 0.1096\n",
      "Epoch 2/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 84ms/step - loss: 0.1082 - val_loss: 0.1100\n",
      "Epoch 3/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m401s\u001b[0m 91ms/step - loss: 0.1078 - val_loss: 0.1096\n",
      "Epoch 4/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m392s\u001b[0m 89ms/step - loss: 0.1076 - val_loss: 0.1087\n",
      "Epoch 5/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 88ms/step - loss: 0.1076 - val_loss: 0.1120\n",
      "Epoch 6/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 81ms/step - loss: 0.1075 - val_loss: 0.1089\n",
      "Epoch 7/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 82ms/step - loss: 0.1074 - val_loss: 0.1085\n",
      "Epoch 8/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 80ms/step - loss: 0.1072 - val_loss: 0.1088\n",
      "Epoch 9/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 80ms/step - loss: 0.1071 - val_loss: 0.1081\n",
      "Epoch 10/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 89ms/step - loss: 0.1070 - val_loss: 0.1081\n",
      "Epoch 11/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 93ms/step - loss: 0.1069 - val_loss: 0.1079\n",
      "Epoch 12/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 96ms/step - loss: 0.1068 - val_loss: 0.1078\n",
      "Epoch 13/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m387s\u001b[0m 88ms/step - loss: 0.1067 - val_loss: 0.1078\n",
      "Epoch 14/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 84ms/step - loss: 0.1066 - val_loss: 0.1077\n",
      "Epoch 15/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 88ms/step - loss: 0.1065 - val_loss: 0.1078\n",
      "Epoch 16/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 77ms/step - loss: 0.1064 - val_loss: 0.1074\n",
      "Epoch 17/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 80ms/step - loss: 0.1064 - val_loss: 0.1073\n",
      "Epoch 18/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 80ms/step - loss: 0.1063 - val_loss: 0.1073\n",
      "Epoch 19/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 80ms/step - loss: 0.1063 - val_loss: 0.1069\n",
      "Epoch 20/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 79ms/step - loss: 6574145.0000 - val_loss: 0.1065\n",
      "Epoch 21/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m395s\u001b[0m 90ms/step - loss: 0.1063 - val_loss: 0.1063\n",
      "Epoch 22/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 93ms/step - loss: 0.1141 - val_loss: 0.1061\n",
      "Epoch 23/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 93ms/step - loss: 0.1061 - val_loss: 0.1061\n",
      "Epoch 24/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 85ms/step - loss: 0.1061 - val_loss: 0.1061\n",
      "Epoch 25/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 93ms/step - loss: 0.1060 - val_loss: 0.1061\n",
      "Epoch 26/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 84ms/step - loss: 0.1060 - val_loss: 0.1061\n",
      "Epoch 27/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 85ms/step - loss: 0.1060 - val_loss: 0.1061\n",
      "Epoch 28/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 85ms/step - loss: 0.1060 - val_loss: 0.1060\n",
      "Epoch 29/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m378s\u001b[0m 86ms/step - loss: 0.1059 - val_loss: 0.1060\n",
      "Epoch 30/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 86ms/step - loss: 0.1065 - val_loss: 0.1060\n",
      "Epoch 31/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 77ms/step - loss: 0.1060 - val_loss: 0.1060\n",
      "Epoch 32/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 84ms/step - loss: 0.1059 - val_loss: 0.1060\n",
      "Epoch 33/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 84ms/step - loss: 0.1059 - val_loss: 0.1060\n",
      "Epoch 34/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 87ms/step - loss: 25344430080.0000 - val_loss: 0.1101\n",
      "Epoch 35/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m393s\u001b[0m 90ms/step - loss: 0.1288 - val_loss: 0.1079\n",
      "Epoch 36/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 81ms/step - loss: 0.1093 - val_loss: 0.1064\n",
      "Epoch 37/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 85ms/step - loss: 0.1063 - val_loss: 0.1061\n",
      "Epoch 38/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 85ms/step - loss: 0.1062 - val_loss: 0.1060\n",
      "Epoch 39/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 77ms/step - loss: 0.1061 - val_loss: 0.1059\n",
      "Epoch 40/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 85ms/step - loss: 0.1060 - val_loss: 0.1059\n",
      "Epoch 41/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 87ms/step - loss: 0.1060 - val_loss: 0.1059\n",
      "Epoch 42/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m391s\u001b[0m 89ms/step - loss: 0.1059 - val_loss: 0.1059\n",
      "Epoch 43/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 84ms/step - loss: 0.1103 - val_loss: 0.1083\n",
      "Epoch 44/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 83ms/step - loss: 0.1072 - val_loss: 0.1062\n",
      "Epoch 45/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 85ms/step - loss: 0.1061 - val_loss: 0.1061\n",
      "Epoch 46/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m393s\u001b[0m 89ms/step - loss: 0.1060 - val_loss: 0.1061\n",
      "Epoch 47/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 86ms/step - loss: 0.1060 - val_loss: 0.1061\n",
      "Epoch 48/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 93ms/step - loss: 0.1059 - val_loss: 0.1062\n",
      "Epoch 49/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m355s\u001b[0m 81ms/step - loss: 0.1059 - val_loss: 0.1064\n",
      "Epoch 50/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 82ms/step - loss: 0.1060 - val_loss: 0.1063\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---  RETRAIN THE MODEL (50 EPOCHS) ---\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"\\nModel Training Started with FIXED LEARNING_RATE=0.0001...\")\n",
    "# X_train (with WINDOW_SIZE=100) is assumed to be in memory.\n",
    "history = model.fit(\n",
    "    X_train, X_train, \n",
    "    epochs=50,         \n",
    "    batch_size=32,\n",
    "    validation_split=0.1, \n",
    "    shuffle=False      \n",
    ")\n",
    "\n",
    "# Visualize Training Loss\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('LSTM Autoencoder Loss Plot (Fixed Learning Rate)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fdf2994-618a-4fe1-9641-a79a88ef24fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test sequences (Normal + Anomaly): 164160\n",
      "Total number of true labels: 164160\n",
      "\n",
      "NEW Anomaly Threshold (95th percentile of Normal Loss): 0.110286\n",
      "\n",
      "--- ANOMALY DETECTION RESULTS (WINDOW_SIZE=100) ---\n",
      "Confusion Matrix:\n",
      "[[148940   7037]\n",
      " [  8001    182]]\n",
      "Accuracy: 0.9084\n",
      "F1 Score: 0.0236\n",
      "Recall (Sensitivity): 0.0222\n"
     ]
    }
   ],
   "source": [
    "# ---  EVALUATION FOR WINDOW_SIZE=100 ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, recall_score\n",
    "\n",
    "# --- NOTE ---\n",
    "# This code assumes X_all, y_true, X_train, and is_fall_train/test are in memory.\n",
    "# It also assumes the trained 'model' and the new WINDOW_SIZE=100 are defined.\n",
    "\n",
    "WINDOW_SIZE = 100 # Ensure the correct size is used for indexing\n",
    "\n",
    "# 1. Prepare all sequences (Test Data)\n",
    "# Assuming 'scaled_data_numpy' contains the entire scaled dataset and 'labels_values' contains the true labels\n",
    "X_all = create_sequences(scaled_data_numpy, WINDOW_SIZE)\n",
    "y_true = labels_values.astype(float).astype(int)[WINDOW_SIZE - 1:]\n",
    "\n",
    "print(f\"Total number of test sequences (Normal + Anomaly): {X_all.shape[0]}\")\n",
    "print(f\"Total number of true labels: {len(y_true)}\")\n",
    "\n",
    "# 2. Calculate Reconstruction Loss on ALL data\n",
    "X_pred = model.predict(X_all, verbose=0)\n",
    "mse_loss = np.mean(np.square(X_all - X_pred), axis=(1, 2))\n",
    "\n",
    "# 3. Determine the NEW Anomaly Threshold (95th percentile of normal training loss)\n",
    "# We must use the loss from the data the model was trained on (X_train)\n",
    "X_train_pred = model.predict(X_train, verbose=0)\n",
    "train_mse = np.mean(np.square(X_train - X_train_pred), axis=(1, 2))\n",
    "\n",
    "# Filter out only the 'Normal' losses from the training set\n",
    "normal_loss = pd.Series(train_mse) \n",
    "# Note: Since X_train contains only normal data, we can directly use train_mse\n",
    "THRESHOLD = np.quantile(normal_loss, 0.95) \n",
    "\n",
    "print(f\"\\nNEW Anomaly Threshold (95th percentile of Normal Loss): {THRESHOLD:.6f}\")\n",
    "\n",
    "# 4. Create Error DataFrame and Predict Classes\n",
    "error_df = pd.DataFrame({'Reconstruction_Error': mse_loss, 'True_Class': y_true})\n",
    "error_df['Predicted_Class'] = (error_df['Reconstruction_Error'] > THRESHOLD).astype(int)\n",
    "\n",
    "# 5. Calculate and Print Final Metrics\n",
    "conf_matrix = confusion_matrix(error_df['True_Class'], error_df['Predicted_Class'])\n",
    "accuracy = accuracy_score(error_df['True_Class'], error_df['Predicted_Class'])\n",
    "f1 = f1_score(error_df['True_Class'], error_df['Predicted_Class'])\n",
    "recall = recall_score(error_df['True_Class'], error_df['Predicted_Class'])\n",
    "\n",
    "print(\"\\n--- ANOMALY DETECTION RESULTS (WINDOW_SIZE=100) ---\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Recall (Sensitivity): {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2de5997d-7626-4f3a-bb5e-174928a40e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">69,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">903</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m69,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector_3 (\u001b[38;5;33mRepeatVector\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │           \u001b[38;5;34m903\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">251,783</span> (983.53 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m251,783\u001b[0m (983.53 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">251,783</span> (983.53 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m251,783\u001b[0m (983.53 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model has been rebuilt as a DEEP LSTM Autoencoder (two layers).\n"
     ]
    }
   ],
   "source": [
    "# ---  REBUILD MODEL AS DEEP LSTM AUTOENCODER ---\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, RepeatVector, TimeDistributed\n",
    "\n",
    "# WINDOW_SIZE = 100 ve NUM_FEATURES = 7 olarak varsayılır.\n",
    "\n",
    "def create_deep_lstm_autoencoder(window_size, num_features):\n",
    "    model = Sequential([\n",
    "        # Encoder Layer 1 (Output, sonraki katman için dizileri döndürür)\n",
    "        LSTM(units=128, activation='relu', input_shape=(window_size, num_features), return_sequences=True), \n",
    "        # Encoder Layer 2 (Son Durumu (Code) döndürür)\n",
    "        LSTM(units=64, activation='relu'), \n",
    "        \n",
    "        RepeatVector(window_size),\n",
    "        \n",
    "        # Decoder Layer 1\n",
    "        LSTM(units=64, activation='relu', return_sequences=True), \n",
    "        # Decoder Layer 2 (Çıkış katmanına bağlanmak için dizileri döndürür)\n",
    "        LSTM(units=128, activation='relu', return_sequences=True),\n",
    "        \n",
    "        TimeDistributed(Dense(num_features))\n",
    "    ])\n",
    "    \n",
    "    # low learning rate\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='mse')\n",
    "    return model\n",
    "\n",
    "model = create_deep_lstm_autoencoder(WINDOW_SIZE, NUM_FEATURES)\n",
    "model.summary()\n",
    "print(\"\\nModel has been rebuilt as a DEEP LSTM Autoencoder (two layers).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ce4ceba-3e1e-42a4-aa73-13b454f88ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">69,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_4              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">903</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m69,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_11 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector_4 (\u001b[38;5;33mRepeatVector\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_12 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_13 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_4              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │           \u001b[38;5;34m903\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">251,783</span> (983.53 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m251,783\u001b[0m (983.53 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">251,783</span> (983.53 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m251,783\u001b[0m (983.53 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model has been rebuilt with tanh activation and learning rate 0.00001.\n"
     ]
    }
   ],
   "source": [
    "# --- STEP 1: REBUILD MODEL WITH TANH ACTIVATION & ULTRA LOW LEARNING RATE ---\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, RepeatVector, TimeDistributed\n",
    "\n",
    "WINDOW_SIZE = 100 \n",
    "NUM_FEATURES = 7 \n",
    "ACTIVATION_FUNCTION = 'tanh' # tanh instead of relu\n",
    "\n",
    "def create_deep_lstm_autoencoder_final(window_size, num_features):\n",
    "    model = Sequential([\n",
    "        # Encoder Layer 1\n",
    "        LSTM(units=128, activation=ACTIVATION_FUNCTION, input_shape=(window_size, num_features), return_sequences=True), \n",
    "        # Encoder Layer 2\n",
    "        LSTM(units=64, activation=ACTIVATION_FUNCTION), \n",
    "        \n",
    "        RepeatVector(window_size),\n",
    "        \n",
    "        # Decoder Layer 1\n",
    "        LSTM(units=64, activation=ACTIVATION_FUNCTION, return_sequences=True), \n",
    "        # Decoder Layer 2\n",
    "        LSTM(units=128, activation=ACTIVATION_FUNCTION, return_sequences=True),\n",
    "        \n",
    "        TimeDistributed(Dense(num_features))\n",
    "    ])\n",
    "    \n",
    "    # Öğrenme hızı 0.00001\n",
    "    model.compile(optimizer=Adam(learning_rate=0.00001), loss='mse')\n",
    "    return model\n",
    "\n",
    "model = create_deep_lstm_autoencoder_final(WINDOW_SIZE, NUM_FEATURES)\n",
    "model.summary()\n",
    "print(f\"\\nModel has been rebuilt with {ACTIVATION_FUNCTION} activation and learning rate 0.00001.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da24be80-1765-4aab-8d55-9003e41c5f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Training Started with tanh activation...\n",
      "Epoch 1/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m505s\u001b[0m 114ms/step - loss: 0.1207 - val_loss: 0.1137\n",
      "Epoch 2/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1617s\u001b[0m 369ms/step - loss: 0.1099 - val_loss: 0.1118\n",
      "Epoch 3/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m494s\u001b[0m 113ms/step - loss: 0.1088 - val_loss: 0.1109\n",
      "Epoch 4/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 101ms/step - loss: 0.1082 - val_loss: 0.1105\n",
      "Epoch 5/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 100ms/step - loss: 0.1078 - val_loss: 0.1102\n",
      "Epoch 6/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 101ms/step - loss: 0.1076 - val_loss: 0.1099\n",
      "Epoch 7/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 100ms/step - loss: 0.1074 - val_loss: 0.1096\n",
      "Epoch 8/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 100ms/step - loss: 0.1072 - val_loss: 0.1093\n",
      "Epoch 9/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 101ms/step - loss: 0.1071 - val_loss: 0.1088\n",
      "Epoch 10/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 102ms/step - loss: 0.1070 - val_loss: 0.1083\n",
      "Epoch 11/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 101ms/step - loss: 0.1069 - val_loss: 0.1080\n",
      "Epoch 12/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m494s\u001b[0m 112ms/step - loss: 0.1069 - val_loss: 0.1078\n",
      "Epoch 13/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m931s\u001b[0m 212ms/step - loss: 0.1068 - val_loss: 0.1077\n",
      "Epoch 14/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 114ms/step - loss: 0.1068 - val_loss: 0.1076\n",
      "Epoch 15/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m486s\u001b[0m 111ms/step - loss: 0.1067 - val_loss: 0.1076\n",
      "Epoch 16/50\n",
      "\u001b[1m  23/4387\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:53\u001b[0m 109ms/step - loss: 0.1070"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mModel Training Started with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACTIVATION_FUNCTION\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m activation...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m      \u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Visualize Training Loss\u001b[39;00m\n\u001b[32m     14\u001b[39m plt.figure(figsize=(\u001b[32m10\u001b[39m, \u001b[32m4\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/miniconda3/envs/anomaly_project/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/miniconda3/envs/anomaly_project/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:399\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    398\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    401\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/miniconda3/envs/anomaly_project/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:241\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    239\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    240\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    243\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/miniconda3/envs/anomaly_project/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/miniconda3/envs/anomaly_project/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/miniconda3/envs/anomaly_project/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/miniconda3/envs/anomaly_project/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/miniconda3/envs/anomaly_project/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/miniconda3/envs/anomaly_project/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/miniconda3/envs/anomaly_project/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/miniconda3/envs/anomaly_project/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/miniconda3/envs/anomaly_project/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# --- : RETRAIN THE DEEP MODEL (50 EPOCHS) ---\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"\\nModel Training Started with {ACTIVATION_FUNCTION} activation...\")\n",
    "history = model.fit(\n",
    "    X_train, X_train, \n",
    "    epochs=50,         \n",
    "    batch_size=32,\n",
    "    validation_split=0.1, \n",
    "    shuffle=False      \n",
    ")\n",
    "\n",
    "# Visualize Training Loss\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('DEEP LSTM Autoencoder Loss Plot (TANH ACTIVATION)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da221d31-f299-4084-8dc7-3601693b0592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model mimarisi yeniden oluşturuldu.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, RepeatVector, TimeDistributed\n",
    "\n",
    "WINDOW_SIZE = 100 \n",
    "NUM_FEATURES = 7 \n",
    "ACTIVATION_FUNCTION = 'tanh' \n",
    "\n",
    "def create_deep_lstm_autoencoder_final(window_size, num_features):\n",
    "    \n",
    "    model = Sequential([\n",
    "        LSTM(units=128, activation=ACTIVATION_FUNCTION, input_shape=(window_size, num_features), return_sequences=True), \n",
    "        LSTM(units=64, activation=ACTIVATION_FUNCTION), \n",
    "        RepeatVector(window_size),\n",
    "        LSTM(units=64, activation=ACTIVATION_FUNCTION, return_sequences=True), \n",
    "        LSTM(units=128, activation=ACTIVATION_FUNCTION, return_sequences=True),\n",
    "        TimeDistributed(Dense(num_features))\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.00001), loss='mse')\n",
    "    return model\n",
    "\n",
    "model = create_deep_lstm_autoencoder_final(WINDOW_SIZE, NUM_FEATURES)\n",
    "print(\"The model architecture has been rebuilt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e1a86a9-9384-4311-b11c-bf207899966a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eğitim, 15. epoch'tan devam ettiriliyor...\n",
      "Epoch 16/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.1331\n",
      "Epoch 16: val_loss improved from None to 0.11386, saving model to deep_lstm_best_weights.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 111ms/step - loss: 0.1189 - val_loss: 0.1139\n",
      "Epoch 17/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.1108\n",
      "Epoch 17: val_loss improved from 0.11386 to 0.11174, saving model to deep_lstm_best_weights.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m473s\u001b[0m 108ms/step - loss: 0.1099 - val_loss: 0.1117\n",
      "Epoch 18/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.1090\n",
      "Epoch 18: val_loss improved from 0.11174 to 0.11115, saving model to deep_lstm_best_weights.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m471s\u001b[0m 107ms/step - loss: 0.1086 - val_loss: 0.1111\n",
      "Epoch 19/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.1082\n",
      "Epoch 19: val_loss improved from 0.11115 to 0.11054, saving model to deep_lstm_best_weights.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m494s\u001b[0m 113ms/step - loss: 0.1080 - val_loss: 0.1105\n",
      "Epoch 20/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.1078\n",
      "Epoch 20: val_loss improved from 0.11054 to 0.10986, saving model to deep_lstm_best_weights.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 100ms/step - loss: 0.1077 - val_loss: 0.1099\n",
      "Epoch 21/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.1075\n",
      "Epoch 21: val_loss improved from 0.10986 to 0.10945, saving model to deep_lstm_best_weights.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 100ms/step - loss: 0.1074 - val_loss: 0.1094\n",
      "Epoch 22/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.1073\n",
      "Epoch 22: val_loss improved from 0.10945 to 0.10935, saving model to deep_lstm_best_weights.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 100ms/step - loss: 0.1072 - val_loss: 0.1093\n",
      "Epoch 23/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.1072\n",
      "Epoch 23: val_loss did not improve from 0.10935\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m473s\u001b[0m 108ms/step - loss: 0.1071 - val_loss: 0.1096\n",
      "Epoch 24/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.1070\n",
      "Epoch 24: val_loss did not improve from 0.10935\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 106ms/step - loss: 0.1070 - val_loss: 0.1096\n",
      "Epoch 25/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.1070\n",
      "Epoch 25: val_loss improved from 0.10935 to 0.10933, saving model to deep_lstm_best_weights.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 101ms/step - loss: 0.1069 - val_loss: 0.1093\n",
      "Epoch 26/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.1069\n",
      "Epoch 26: val_loss improved from 0.10933 to 0.10881, saving model to deep_lstm_best_weights.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 111ms/step - loss: 0.1069 - val_loss: 0.1088\n",
      "Epoch 27/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.1068\n",
      "Epoch 27: val_loss improved from 0.10881 to 0.10839, saving model to deep_lstm_best_weights.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m570s\u001b[0m 130ms/step - loss: 0.1068 - val_loss: 0.1084\n",
      "Epoch 28/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.1068\n",
      "Epoch 28: val_loss improved from 0.10839 to 0.10811, saving model to deep_lstm_best_weights.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m611s\u001b[0m 139ms/step - loss: 0.1068 - val_loss: 0.1081\n",
      "Epoch 29/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.1067\n",
      "Epoch 29: val_loss improved from 0.10811 to 0.10803, saving model to deep_lstm_best_weights.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m534s\u001b[0m 122ms/step - loss: 0.1068 - val_loss: 0.1080\n",
      "Epoch 30/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.1067\n",
      "Epoch 30: val_loss improved from 0.10803 to 0.10801, saving model to deep_lstm_best_weights.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m585s\u001b[0m 133ms/step - loss: 0.1067 - val_loss: 0.1080\n",
      "Epoch 31/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.1067\n",
      "Epoch 31: val_loss improved from 0.10801 to 0.10792, saving model to deep_lstm_best_weights.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m615s\u001b[0m 140ms/step - loss: 0.1067 - val_loss: 0.1079\n",
      "Epoch 32/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.1066\n",
      "Epoch 32: val_loss improved from 0.10792 to 0.10774, saving model to deep_lstm_best_weights.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m567s\u001b[0m 129ms/step - loss: 0.1067 - val_loss: 0.1077\n",
      "Epoch 33/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.1066\n",
      "Epoch 33: val_loss improved from 0.10774 to 0.10756, saving model to deep_lstm_best_weights.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m534s\u001b[0m 122ms/step - loss: 0.1066 - val_loss: 0.1076\n",
      "Epoch 34/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.1066\n",
      "Epoch 34: val_loss improved from 0.10756 to 0.10742, saving model to deep_lstm_best_weights.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m529s\u001b[0m 121ms/step - loss: 0.1066 - val_loss: 0.1074\n",
      "Epoch 35/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.1065\n",
      "Epoch 35: val_loss improved from 0.10742 to 0.10721, saving model to deep_lstm_best_weights.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 102ms/step - loss: 0.1065 - val_loss: 0.1072\n",
      "Epoch 36/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.1065\n",
      "Epoch 36: val_loss improved from 0.10721 to 0.10710, saving model to deep_lstm_best_weights.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m506s\u001b[0m 115ms/step - loss: 0.1065 - val_loss: 0.1071\n",
      "Epoch 37/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.1065\n",
      "Epoch 37: val_loss improved from 0.10710 to 0.10699, saving model to deep_lstm_best_weights.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 116ms/step - loss: 0.1065 - val_loss: 0.1070\n",
      "Epoch 38/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.1065\n",
      "Epoch 38: val_loss improved from 0.10699 to 0.10690, saving model to deep_lstm_best_weights.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m617s\u001b[0m 141ms/step - loss: 0.1065 - val_loss: 0.1069\n",
      "Epoch 39/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.1064\n",
      "Epoch 39: val_loss improved from 0.10690 to 0.10685, saving model to deep_lstm_best_weights.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m593s\u001b[0m 135ms/step - loss: 0.1065 - val_loss: 0.1069\n",
      "Epoch 40/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.1064\n",
      "Epoch 40: val_loss improved from 0.10685 to 0.10684, saving model to deep_lstm_best_weights.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 106ms/step - loss: 0.1064 - val_loss: 0.1068\n",
      "Epoch 41/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.1064\n",
      "Epoch 41: val_loss did not improve from 0.10684\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m461s\u001b[0m 105ms/step - loss: 0.1064 - val_loss: 0.1068\n",
      "Epoch 42/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.1064\n",
      "Epoch 42: val_loss did not improve from 0.10684\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m534s\u001b[0m 122ms/step - loss: 0.1064 - val_loss: 0.1069\n",
      "Epoch 43/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.1063\n",
      "Epoch 43: val_loss did not improve from 0.10684\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 116ms/step - loss: 0.1064 - val_loss: 0.1069\n",
      "Epoch 44/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.1063\n",
      "Epoch 44: val_loss did not improve from 0.10684\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m469s\u001b[0m 107ms/step - loss: 0.1063 - val_loss: 0.1069\n",
      "Epoch 45/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.1063\n",
      "Epoch 45: val_loss did not improve from 0.10684\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m539s\u001b[0m 123ms/step - loss: 0.1063 - val_loss: 0.1069\n",
      "Epoch 46/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.1063\n",
      "Epoch 46: val_loss did not improve from 0.10684\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m540s\u001b[0m 123ms/step - loss: 0.1063 - val_loss: 0.1069\n",
      "Epoch 47/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.1062\n",
      "Epoch 47: val_loss did not improve from 0.10684\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m506s\u001b[0m 115ms/step - loss: 0.1062 - val_loss: 0.1069\n",
      "Epoch 48/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.1062\n",
      "Epoch 48: val_loss did not improve from 0.10684\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 106ms/step - loss: 0.1062 - val_loss: 0.1069\n",
      "Epoch 49/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.1062\n",
      "Epoch 49: val_loss did not improve from 0.10684\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m512s\u001b[0m 117ms/step - loss: 0.1062 - val_loss: 0.1070\n",
      "Epoch 50/50\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.1062\n",
      "Epoch 50: val_loss did not improve from 0.10684\n",
      "\u001b[1m4387/4387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m593s\u001b[0m 135ms/step - loss: 0.1062 - val_loss: 0.1070\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# The weights trained over 15 epochs are still in RAM in the \"model\" object.\n",
    "# That's why we use model.set_weights() instead of model.load_weights().\n",
    "\n",
    "\n",
    "filepath=\"deep_lstm_best_weights.weights.h5\" \n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print(\"\\ntraining continues from the 15th epoch...\")\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, X_train, \n",
    "    epochs=50,         \n",
    "    batch_size=32,\n",
    "    validation_split=0.1, \n",
    "    shuffle=False,\n",
    "    callbacks=callbacks_list,\n",
    "    # KRİTİK AYAR: Keras'a 15. epoc'tan devam etmesini söylüyoruz.\n",
    "    initial_epoch=15  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a53aeffe-335b-4f72-a4bb-54c8b71889f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NEW Anomaly Threshold (95th percentile of Normal Loss): 0.110690\n",
      "\n",
      "--- ANOMALY DETECTION RESULTS (DEEP LSTM, TANH) ---\n",
      "Confusion Matrix:\n",
      "[[148958   7019]\n",
      " [  7958    225]]\n",
      "Accuracy: 0.9088\n",
      "F1 Score: 0.0292\n",
      "Recall (Sensitivity): 0.0275\n"
     ]
    }
   ],
   "source": [
    "# ---EVALUATION FOR DEEP LSTM MODEL (TANH) ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, recall_score\n",
    "\n",
    "# --- NOTE ---\n",
    "# This code assumes X_all, y_true, X_train, and the trained 'model' are defined in memory.\n",
    "\n",
    "WINDOW_SIZE = 100 \n",
    "\n",
    "# Calculate Reconstruction Loss on ALL data\n",
    "# X_all (all test data sequences)\n",
    "X_pred = model.predict(X_all, verbose=0)\n",
    "mse_loss = np.mean(np.square(X_all - X_pred), axis=(1, 2))\n",
    "\n",
    "# Determine the NEW Anomaly Threshold (95th percentile of normal training loss)\n",
    "# X_train (training sequences from normal data only)\n",
    "X_train_pred = model.predict(X_train, verbose=0)\n",
    "train_mse = np.mean(np.square(X_train - X_train_pred), axis=(1, 2))\n",
    "\n",
    "# Calculate the 95th percentile threshold\n",
    "normal_loss = pd.Series(train_mse) \n",
    "THRESHOLD = np.quantile(normal_loss, 0.95) \n",
    "\n",
    "print(f\"\\nNEW Anomaly Threshold (95th percentile of Normal Loss): {THRESHOLD:.6f}\")\n",
    "\n",
    "# Predict Classes\n",
    "error_df = pd.DataFrame({'Reconstruction_Error': mse_loss, 'True_Class': y_true})\n",
    "error_df['Predicted_Class'] = (error_df['Reconstruction_Error'] > THRESHOLD).astype(int)\n",
    "\n",
    "# Calculate and Print Final Metrics\n",
    "conf_matrix = confusion_matrix(error_df['True_Class'], error_df['Predicted_Class'])\n",
    "accuracy = accuracy_score(error_df['True_Class'], error_df['Predicted_Class'])\n",
    "f1 = f1_score(error_df['True_Class'], error_df['Predicted_Class'])\n",
    "recall = recall_score(error_df['True_Class'], error_df['Predicted_Class'])\n",
    "\n",
    "print(\"\\n--- ANOMALY DETECTION RESULTS (DEEP LSTM, TANH) ---\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Recall (Sensitivity): {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c0371e-a3c0-4f8f-ba63-c7267230f71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#This project employed a Deep Learning methodology using an \n",
    "#LSTM Autoencoder architecture for fall detection in sensor data. The initial \n",
    "#Single-Layer ReLU model suffered \n",
    "#from low performance (Recall} < 4) and \n",
    "#severe Nan Errors (Exploding Gradients). To stabilize and \n",
    "#optimize the model, a \n",
    "#progressive series of architectural #changes were implemented, including:\n",
    "\n",
    "* #Learning Rate Reduction #to {0.0001} from {0.001} \n",
    "#to ensure training stability.\n",
    "* #Window Size Increase #from {50} to {100} to provide better temporal context.\n",
    "* #Transition to a Deep LSTM Architecture (two Encoder/Decoder layers) \n",
    "#to enhance feature extraction.\n",
    "* #Switching the Activation Function to Tanh \n",
    "#and applying an Ultra-Low Learning Rate ({0.00001}) \n",
    "#to resolve persistent Nan errors.\n",
    "\n",
    "#Despite these comprehensive optimizations, the model's final \n",
    "#Recall (Sensitivity) score for \n",
    "#fall detection remained critically \n",
    "#low at {2.75\\%}. This result demonstrates that the \n",
    "#LSTM Autoencoder is an unsuitable unsupervised method for \n",
    "#reliably distinguishing the fall event from high-noise, complex \n",
    "#time-series data in this specific dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
